{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e04bdcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "# load tokenizer \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6bb958ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before preprocessing: \n",
      "\n",
      "@philly European Central Bank goes bullish on bitcoin: â€œ[â€¦] recent developments, such as the listing of Bitcoin futures contracts by US exchanges, could lead European banks too to hold positions in Bitcoin, and therefore we will certainly look at that,â€ - ECB President Mario Draghi  https://t.co/lDgJU1H2X1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'philly european central bank goes bullish on bitcoin: ] recent developments such as the listing of bitcoin futures contracts by us exchanges could lead european banks too to hold positions in bitcoin and therefore we will certainly look at that - ecb president mario draghi  '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = '@philly European Central Bank goes bullish on bitcoin: â€œ[â€¦] recent developments, such as the listing of Bitcoin futures contracts by US exchanges, could lead European banks too to hold positions in Bitcoin, and therefore we will certainly look at that,â€ - ECB President Mario Draghi  https://t.co/lDgJU1H2X1'\n",
    "print('before preprocessing: \\n\\n'+sentence)\n",
    "\n",
    "# apply the following preprocessing techniques on the data \n",
    "import re \n",
    "# lowercase all characters \n",
    "sentence = sentence.lower()\n",
    "\n",
    "# remove URL's \n",
    "sentence = re.sub(r\"http\\S+\", '', sentence)\n",
    "sentence = re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", '', sentence)\n",
    "\n",
    "# remove HTML reference characters \n",
    "sentence = re.sub(r\"&[a-z]+;\", '', sentence)\n",
    "\n",
    "# remove non english letters \n",
    "sentence = re.sub(r\"[^a-z\\s\\(\\-:\\)\\\\\\/\\];='#]\", '', sentence)\n",
    "sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(test_sentence))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(test_sentence)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
