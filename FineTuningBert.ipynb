{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3357b916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 09:32:23.968882: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd63ec5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 09:32:26.841384: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-02 09:32:26.855731: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-03-02 09:32:26.935887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-02 09:32:26.936482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1070 computeCapability: 6.1\n",
      "coreClock: 1.7845GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s\n",
      "2022-03-02 09:32:26.936536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-02 09:32:27.003454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-02 09:32:27.003608: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-03-02 09:32:27.039682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-02 09:32:27.048904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-02 09:32:27.118085: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-02 09:32:27.128244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-02 09:32:27.250931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-02 09:32:27.251270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-02 09:32:27.251988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-02 09:32:27.252433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-03-02 09:32:27.253576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-02 09:32:28.940875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-02 09:32:28.940912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-03-02 09:32:28.940922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-03-02 09:32:28.942047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-02 09:32:28.942319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-02 09:32:28.942541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-02 09:32:28.942710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 7168 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2022-03-02 09:32:28.946104: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c288713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc3eaae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>@tippin_me @karozagorus I give 5 satoshis to e...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>@hitbtc @bkargili Attention hit btc does scam ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>BTC(„Éì„ÉÉ„Éà„Ç≥„Ç§„É≥)„Åå95‰∏áÂÜÜË∂Ö„Åà„Å¶„Åæ„Åô„ÇÑ„Çì‚Ä¶ https://t.co/uzXGkzKDcI</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>@CryptoGainz1 Yep https://t.co/TrpbxApU3H</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>@Kexkey @hodlwallet We‚Äôll miss you, but we won...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0        Date                                               text  \\\n",
       "0          0  2019-05-27  @tippin_me @karozagorus I give 5 satoshis to e...   \n",
       "1          1  2019-05-27  @hitbtc @bkargili Attention hit btc does scam ...   \n",
       "2          2  2019-05-27   BTC(„Éì„ÉÉ„Éà„Ç≥„Ç§„É≥)„Åå95‰∏áÂÜÜË∂Ö„Åà„Å¶„Åæ„Åô„ÇÑ„Çì‚Ä¶ https://t.co/uzXGkzKDcI   \n",
       "3          3  2019-05-27          @CryptoGainz1 Yep https://t.co/TrpbxApU3H   \n",
       "4          4  2019-05-27  @Kexkey @hodlwallet We‚Äôll miss you, but we won...   \n",
       "\n",
       "  Sentiment  \n",
       "0  Positive  \n",
       "1  Positive  \n",
       "2  Positive  \n",
       "3  Positive  \n",
       "4  Positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the training data into df \n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('CSVFiles/training-data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd52586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aafd7c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Sentiment Score')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=df.Sentiment)\n",
    "plt.xlabel('Sentiment Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6e826ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface in /home/phil81/anaconda3/envs/tf-gpu/lib/python3.9/site-packages (0.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "# install hugging face library to use their transformers package \n",
    "!pip install huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5d72644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 10,006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0])) # we have 10,006 total sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd13ef86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hackers delight: 2017 bitcoin mania led to exp...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>1979</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>O valor do Bitcoin caiu :( - R$34000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>2719</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>Another hour! It's #WEALTHGENERATION TIME get ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7077</th>\n",
       "      <td>7077</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>VanEck Bitcoin (BTC) ETF Verdict Delayed By Th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>3298</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>Worrying about monopolies in tech is not produ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>580</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>Moonday Mornings: Microsoft helped Louis Vuitt...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3570</th>\n",
       "      <td>3570</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>Lol Kevin on CNBC crack me up . Calling bitcoi...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9820</th>\n",
       "      <td>9814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/dNWfSgjtJ2 #PDATA #Opirium #ether...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6395</th>\n",
       "      <td>6395</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>@tylerwinklevoss As long as the #Bitcoin commu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>3008</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>#ooobtc #obx #IEO #exchange #crypto #bitcoin #...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        Date  \\\n",
       "9996       9990         NaN   \n",
       "1979       1979  2019-05-27   \n",
       "2719       2719  2019-05-27   \n",
       "7077       7077  2019-05-21   \n",
       "3298       3298  2019-05-27   \n",
       "580         580  2019-05-27   \n",
       "3570       3570  2019-05-27   \n",
       "9820       9814         NaN   \n",
       "6395       6395  2019-05-21   \n",
       "3008       3008  2019-05-27   \n",
       "\n",
       "                                                   text  Sentiment  \n",
       "9996  Hackers delight: 2017 bitcoin mania led to exp...        1.0  \n",
       "1979               O valor do Bitcoin caiu :( - R$34000        2.0  \n",
       "2719  Another hour! It's #WEALTHGENERATION TIME get ...        2.0  \n",
       "7077  VanEck Bitcoin (BTC) ETF Verdict Delayed By Th...        0.0  \n",
       "3298  Worrying about monopolies in tech is not produ...        2.0  \n",
       "580   Moonday Mornings: Microsoft helped Louis Vuitt...        2.0  \n",
       "3570  Lol Kevin on CNBC crack me up . Calling bitcoi...        2.0  \n",
       "9820  https://t.co/dNWfSgjtJ2 #PDATA #Opirium #ether...        1.0  \n",
       "6395  @tylerwinklevoss As long as the #Bitcoin commu...        0.0  \n",
       "3008  #ooobtc #obx #IEO #exchange #crypto #bitcoin #...        2.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.replace({'Sentiment': {'Negative':0, 'Neutral':1, 'Positive':2}})  \n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7cbfd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# now we want to format our data so that VERT can use it for training \n",
    "from transformers import BertTokenizer \n",
    "\n",
    "# load the BERT tokenizer \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7671e474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:    I give 5 satoshis to everyone for free and without any conditions. \n",
      "\n",
      "So anyone can instantly start using and learning Bitcoin without any initial investment.üéâ\n",
      "\n",
      "#Bitcoin #MassAdoption #LightningNetwork\n",
      "Tokenized:  ['i', 'give', '5', 'sato', '##shi', '##s', 'to', 'everyone', 'for', 'free', 'and', 'without', 'any', 'conditions', '.', 'so', 'anyone', 'can', 'instantly', 'start', 'using', 'and', 'learning', 'bit', '##co', '##in', 'without', 'any', 'initial', 'investment', '.', '[UNK]', '#', 'bit', '##co', '##in', '#', 'mass', '##ado', '##ption', '#', 'lightning', '##net', '##work']\n",
      "Token IDs:  [1045, 2507, 1019, 20251, 6182, 2015, 2000, 3071, 2005, 2489, 1998, 2302, 2151, 3785, 1012, 2061, 3087, 2064, 6880, 2707, 2478, 1998, 4083, 2978, 3597, 2378, 2302, 2151, 3988, 5211, 1012, 100, 1001, 2978, 3597, 2378, 1001, 3742, 9365, 16790, 1001, 7407, 7159, 6198]\n"
     ]
    }
   ],
   "source": [
    "# some regex to clean the data before passing it to BERT tokenizer  \n",
    "import re \n",
    "df = df.replace(to_replace='https?:\\/\\/\\S+', value='', regex=True) # remove https urls \n",
    "df = df.replace(to_replace=\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", value='', regex=True) # remove www urls \n",
    "df = df.replace(to_replace=\"\\[video\\]\", value='', regex=True) # remove videos that got replaced with [video]\n",
    "df = df.replace(to_replace='{link}', value='', regex=True) # remove links \n",
    "df = df.replace(to_replace='&[a-z]+;', value='', regex=True) # remove HTML embedded characters\n",
    "df = df.replace(to_replace='@[^ ]+', value='', regex=True) # remove @usernames \n",
    "\n",
    "# some sample output \n",
    "tweets = df.text.values \n",
    "labels = df.Sentiment.values \n",
    "import numpy as np\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(' Original: ', tweets[0])\n",
    "print('Tokenized: ', tokenizer.tokenize(tweets[0]))\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweets[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84df8866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>I give 5 satoshis to everyone for free and w...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>Attention hit btc does scam with me and not ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>BTC(„Éì„ÉÉ„Éà„Ç≥„Ç§„É≥)„Åå95‰∏áÂÜÜË∂Ö„Åà„Å¶„Åæ„Åô„ÇÑ„Çì‚Ä¶</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>Yep</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>We‚Äôll miss you, but we won‚Äôt let our ideolog...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes - the term colored coin comes from the ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0 to 50% ‚Äì Time to Pay Crypto Taxes in the Eur...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RT  Chinese Exchange Bitasia Now Supports 0-Co...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Niceüí∞</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bitcoin Cash Price Technical Analysis ‚Äì BCH/US...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10006 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date                                               text  \\\n",
       "0      2019-05-27    I give 5 satoshis to everyone for free and w...   \n",
       "1      2019-05-27    Attention hit btc does scam with me and not ...   \n",
       "2      2019-05-27                          BTC(„Éì„ÉÉ„Éà„Ç≥„Ç§„É≥)„Åå95‰∏áÂÜÜË∂Ö„Åà„Å¶„Åæ„Åô„ÇÑ„Çì‚Ä¶    \n",
       "3      2019-05-27                                               Yep    \n",
       "4      2019-05-27    We‚Äôll miss you, but we won‚Äôt let our ideolog...   \n",
       "...           ...                                                ...   \n",
       "10001         NaN     Yes - the term colored coin comes from the ...   \n",
       "10002         NaN  0 to 50% ‚Äì Time to Pay Crypto Taxes in the Eur...   \n",
       "10003         NaN  RT  Chinese Exchange Bitasia Now Supports 0-Co...   \n",
       "10004         NaN                                             Niceüí∞    \n",
       "10005         NaN  Bitcoin Cash Price Technical Analysis ‚Äì BCH/US...   \n",
       "\n",
       "       Sentiment  \n",
       "0            2.0  \n",
       "1            2.0  \n",
       "2            2.0  \n",
       "3            2.0  \n",
       "4            2.0  \n",
       "...          ...  \n",
       "10001        1.0  \n",
       "10002        1.0  \n",
       "10003        1.0  \n",
       "10004        1.0  \n",
       "10005        1.0  \n",
       "\n",
       "[10006 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Unnamed: 0'],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9819325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length:  203\n"
     ]
    }
   ],
   "source": [
    "max_len = 0 \n",
    "\n",
    "for i in range(len(tweets)):\n",
    "    # tokenize the text and add `[CLS]` and `[SEP]` tokens \n",
    "    input_ids = tokenizer.encode(str(tweets[i]), add_special_tokens=True)\n",
    "    \n",
    "    #update max sentence length\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "    \n",
    "print('max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86bb16fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phil81/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:    I give 5 satoshis to everyone for free and without any conditions. \n",
      "\n",
      "So anyone can instantly start using and learning Bitcoin without any initial investment.üéâ\n",
      "\n",
      "#Bitcoin #MassAdoption #LightningNetwork\n",
      "Token IDs: tensor([  101,  1045,  2507,  1019, 20251,  6182,  2015,  2000,  3071,  2005,\n",
      "         2489,  1998,  2302,  2151,  3785,  1012,  2061,  3087,  2064,  6880,\n",
      "         2707,  2478,  1998,  4083,  2978,  3597,  2378,  2302,  2151,  3988,\n",
      "         5211,  1012,   100,  1001,  2978,  3597,  2378,  1001,  3742,  9365,\n",
      "        16790,  1001,  7407,  7159,  6198,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "# we will set max_len to 235 \n",
    "# now we can perform tokenization \n",
    "input_ids = [] \n",
    "attention_masks = [] \n",
    "\n",
    "for i in range(len(tweets)):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        str(tweets[i]),                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    # add encoded sentence to list \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    # add attention masks to list \n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "#convert the lists into tensors \n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "print('Original: ', tweets[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b1e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will not divide our training data into training and validation sets (90/10)\n",
    "from torch.utils.data import TensorDataset, random_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e91f46b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9,005 training samples\n",
      "1,001 validation samples\n"
     ]
    }
   ],
   "source": [
    "# combine training inputs into a training dataset \n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "training_size = int(0.9*len(dataset))\n",
    "validation_size = len(dataset) - training_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "training_dataset, validation_dataset = random_split(dataset, [training_size, validation_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(training_size))\n",
    "print('{:>5,} validation samples'.format(validation_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfe7b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            training_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(training_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            validation_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(validation_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbe244e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have properly formatted our input data, we are going to fine-tune the BERT model \n",
    "# huggincgface pytorch has many interfaces designed for NLP tasks (BertForSequenceClassification)\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e45fb84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
